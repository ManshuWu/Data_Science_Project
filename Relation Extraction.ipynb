{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T13:05:50.535905Z",
     "iopub.status.busy": "2025-08-19T13:05:50.535634Z",
     "iopub.status.idle": "2025-08-19T13:05:50.902729Z",
     "shell.execute_reply": "2025-08-19T13:05:50.901946Z",
     "shell.execute_reply.started": "2025-08-19T13:05:50.535879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = Path(\"/kaggle/input/fullfull/annotations\")\n",
    "OUTPUT_FILE = Path(\"merged_full.jsonl\") \n",
    "\n",
    "merged = []\n",
    "\n",
    "for full_path in sorted(INPUT_DIR.glob(\"*_full.jsonl\")):\n",
    "    filename = full_path.name\n",
    "    with full_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for lineno, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                print(f\"Skipping empty line at {filename}:{lineno}\")\n",
    "                continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error at {filename}:{lineno} — {e}\")\n",
    "                continue\n",
    "\n",
    "            text = rec.get(\"text\", \"\")\n",
    "            spans = rec.get(\"spans\", [])\n",
    "            relations = rec.get(\"relations\", [])\n",
    "\n",
    "            if not spans:\n",
    "                continue\n",
    "\n",
    "            merged.append({\n",
    "                \"text\": text,\n",
    "                \"spans\": spans,\n",
    "                \"relations\": relations\n",
    "            })\n",
    "\n",
    "with OUTPUT_FILE.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for entry in merged:\n",
    "        fw.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Merged and saved {len(merged)} records (text + spans + relations) to: {OUTPUT_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T13:55:20.785797Z",
     "iopub.status.busy": "2025-08-19T13:55:20.785530Z",
     "iopub.status.idle": "2025-08-19T13:55:20.964602Z",
     "shell.execute_reply": "2025-08-19T13:55:20.963801Z",
     "shell.execute_reply.started": "2025-08-19T13:55:20.785778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = Path(\"/kaggle/input/fullfull/annotations\")\n",
    "OUTPUT_FILE = Path(\"merged_full.jsonl\")  \n",
    "\n",
    "merged = []\n",
    "relation_count = 0  \n",
    "\n",
    "for full_path in sorted(INPUT_DIR.glob(\"*_full.jsonl\")):\n",
    "    filename = full_path.name\n",
    "    with full_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for lineno, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                print(f\"Skipping empty line at {filename}:{lineno}\")\n",
    "                continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error at {filename}:{lineno} — {e}\")\n",
    "                continue\n",
    "\n",
    "            text = rec.get(\"text\", \"\")\n",
    "            spans = rec.get(\"spans\", [])\n",
    "            relations = rec.get(\"relations\", [])\n",
    "\n",
    "          \n",
    "            if not spans:\n",
    "                continue\n",
    "\n",
    "      \n",
    "            relation_count += len(relations) \n",
    "\n",
    "            merged.append({\n",
    "                \"text\": text,\n",
    "                \"spans\": spans,\n",
    "                \"relations\": relations\n",
    "            })\n",
    "\n",
    "\n",
    "with OUTPUT_FILE.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for entry in merged:\n",
    "        fw.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Merged and saved {len(merged)} records (text + spans + relations) to: {OUTPUT_FILE.resolve()}\")\n",
    "print(f\"Total number of relation labels annotated: {relation_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T13:07:01.206330Z",
     "iopub.status.busy": "2025-08-19T13:07:01.206066Z",
     "iopub.status.idle": "2025-08-19T13:07:01.228256Z",
     "shell.execute_reply": "2025-08-19T13:07:01.227559Z",
     "shell.execute_reply.started": "2025-08-19T13:07:01.206310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "INPUT_FILE = Path(\"merged_full.jsonl\")\n",
    "OUTPUT_FILE = Path(\"relation_binary.jsonl\")\n",
    "\n",
    "relation_data = []\n",
    "\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        text = record.get(\"text\", \"\")\n",
    "        spans = record.get(\"spans\", [])\n",
    "        relations = record.get(\"relations\", [])\n",
    "\n",
    "  \n",
    "        for idx, span in enumerate(spans):\n",
    "            span[\"id\"] = idx\n",
    "\n",
    " \n",
    "        pos2id = {\n",
    "            (span[\"token_start\"], span[\"token_end\"]): span[\"id\"]\n",
    "            for span in spans\n",
    "        }\n",
    "\n",
    "        pos_set = set()\n",
    "        rel_type_map = {}\n",
    "        for rel in relations:\n",
    "  \n",
    "            head_lbl = rel[\"head_span\"].get(\"label\")\n",
    "            child_lbl = rel[\"child_span\"].get(\"label\")\n",
    "            if not (head_lbl == \"PATIENT\" and child_lbl in (\"HPO_TERM\", \"GENE_VARIANT\")):\n",
    "                continue\n",
    "\n",
    "            h_key = (rel[\"head_span\"][\"token_start\"], rel[\"head_span\"][\"token_end\"])\n",
    "            c_key = (rel[\"child_span\"][\"token_start\"], rel[\"child_span\"][\"token_end\"])\n",
    "            if h_key not in pos2id or c_key not in pos2id:\n",
    "                continue\n",
    "\n",
    "            head_id  = pos2id[h_key]\n",
    "            child_id = pos2id[c_key]\n",
    "            pos_set.add((head_id, child_id))\n",
    "            rel_type_map[(head_id, child_id)] = rel.get(\"label\", \"unknown\")\n",
    "\n",
    "\n",
    "        for span1, span2 in product(spans, spans):\n",
    "            if span1[\"id\"] == span2[\"id\"]:\n",
    "                continue\n",
    "            if span1[\"label\"] != \"PATIENT\":\n",
    "                continue\n",
    "            if span2[\"label\"] not in (\"HPO_TERM\", \"GENE_VARIANT\"):\n",
    "                continue\n",
    "\n",
    "            pair = (span1[\"id\"], span2[\"id\"])\n",
    "            label = 1 if pair in pos_set else 0\n",
    "            relation = rel_type_map.get(pair, \"no_relation\")\n",
    "\n",
    "            relation_data.append({\n",
    "                \"text\":       text,\n",
    "                \"head\":       span1[\"text\"],\n",
    "                \"head_type\":  span1[\"label\"],\n",
    "                \"child\":      span2[\"text\"],\n",
    "                \"child_type\": span2[\"label\"],\n",
    "                \"relation\":   relation,\n",
    "                \"label\":      label,\n",
    "            })\n",
    "\n",
    "with OUTPUT_FILE.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for item in relation_data:\n",
    "        fw.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\" Generated {len(relation_data)} relation instances and saved to: {OUTPUT_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T14:28:29.883033Z",
     "iopub.status.busy": "2025-08-19T14:28:29.882631Z",
     "iopub.status.idle": "2025-08-19T14:28:29.895215Z",
     "shell.execute_reply": "2025-08-19T14:28:29.894550Z",
     "shell.execute_reply.started": "2025-08-19T14:28:29.883005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Input file\n",
    "INPUT_FILE = Path(\"relation_binary.jsonl\")\n",
    "\n",
    "# Output files\n",
    "POSITIVES_FILE = Path(\"positives_triples.jsonl\")\n",
    "NEGATIVES_FILE = Path(\"negatives_triples.jsonl\")\n",
    "\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as infile, \\\n",
    "     POSITIVES_FILE.open(\"w\", encoding=\"utf-8\") as pos_out, \\\n",
    "     NEGATIVES_FILE.open(\"w\", encoding=\"utf-8\") as neg_out:\n",
    "\n",
    "    for line in infile:\n",
    "        rec = json.loads(line)\n",
    "        triple = {\n",
    "            \"head\":       rec[\"head\"],\n",
    "            \"head_type\":  rec[\"head_type\"],\n",
    "            \"child\":      rec[\"child\"],\n",
    "            \"child_type\": rec[\"child_type\"],\n",
    "            \"relation\":   rec[\"relation\"],\n",
    "            \"label\":      rec[\"label\"],\n",
    "        }\n",
    "        if rec.get(\"label\") == 1:\n",
    "            pos_out.write(json.dumps(triple, ensure_ascii=False) + \"\\n\")\n",
    "        else:\n",
    "            neg_out.write(json.dumps(triple, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\" Positive triples saved to: {POSITIVES_FILE.resolve()}\")\n",
    "print(f\" Negative triples saved to: {NEGATIVES_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T13:37:57.853062Z",
     "iopub.status.busy": "2025-08-19T13:37:57.852727Z",
     "iopub.status.idle": "2025-08-19T13:37:57.862407Z",
     "shell.execute_reply": "2025-08-19T13:37:57.861636Z",
     "shell.execute_reply.started": "2025-08-19T13:37:57.853036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "POSITIVES_FILE = Path(\"positives_triples.jsonl\")\n",
    "NEGATIVES_FILE = Path(\"negatives_triples.jsonl\")\n",
    "\n",
    "\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "\n",
    "\n",
    "with POSITIVES_FILE.open(\"r\", encoding=\"utf-8\") as pos_file:\n",
    "    for line in pos_file:\n",
    "        rec = json.loads(line)\n",
    "        if rec.get(\"label\") == 1:\n",
    "            positive_count += 1\n",
    "\n",
    "with NEGATIVES_FILE.open(\"r\", encoding=\"utf-8\") as neg_file:\n",
    "    for line in neg_file:\n",
    "        rec = json.loads(line)\n",
    "        if rec.get(\"label\") == 0:\n",
    "            negative_count += 1\n",
    "\n",
    "\n",
    "total_count = positive_count + negative_count\n",
    "\n",
    "\n",
    "print(f\"Total number of positive instances (label = 1): {positive_count}\")\n",
    "print(f\"Total number of negative instances (label = 0): {negative_count}\")\n",
    "print(f\"Total number of instances: {total_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T15:21:20.373652Z",
     "iopub.status.busy": "2025-08-19T15:21:20.373268Z",
     "iopub.status.idle": "2025-08-19T15:21:20.398482Z",
     "shell.execute_reply": "2025-08-19T15:21:20.397620Z",
     "shell.execute_reply.started": "2025-08-19T15:21:20.373626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "INPUT_FILE = Path(\"merged_full_1.jsonl\")\n",
    "OUTPUT_FILE = Path(\"relation_binary_1.jsonl\")\n",
    "\n",
    "relation_data = []\n",
    "positive_count = 0 \n",
    "negative_count = 0 \n",
    "\n",
    "\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        text = record.get(\"text\", \"\")\n",
    "        spans = record.get(\"spans\", [])\n",
    "        relations = record.get(\"relations\", [])\n",
    "\n",
    "  \n",
    "        for idx, span in enumerate(spans):\n",
    "            span[\"id\"] = idx\n",
    "\n",
    "\n",
    "        pos2id = {\n",
    "            (span[\"token_start\"], span[\"token_end\"]): span[\"id\"]\n",
    "            for span in spans\n",
    "        }\n",
    "\n",
    "\n",
    "        pos_set = set() \n",
    "        for span1, span2 in product(spans, spans):\n",
    "            if span1[\"id\"] == span2[\"id\"]:\n",
    "                continue\n",
    "            if span1[\"label\"] != \"PATIENT\":\n",
    "                continue\n",
    "            if span2[\"label\"] not in (\"HPO_TERM\", \"GENE_VARIANT\"):\n",
    "                continue\n",
    "\n",
    "            pair = (span1[\"id\"], span2[\"id\"])\n",
    "\n",
    "\n",
    "            label = 0\n",
    "            for rel in relations:\n",
    "                head_lbl = rel[\"head_span\"].get(\"label\")\n",
    "                child_lbl = rel[\"child_span\"].get(\"label\")\n",
    "                if head_lbl == \"PATIENT\" and child_lbl in (\"HPO_TERM\", \"GENE_VARIANT\"):\n",
    "                    h_key = (rel[\"head_span\"][\"token_start\"], rel[\"head_span\"][\"token_end\"])\n",
    "                    c_key = (rel[\"child_span\"][\"token_start\"], rel[\"child_span\"][\"token_end\"])\n",
    "                    if h_key == (span1[\"token_start\"], span1[\"token_end\"]) and c_key == (span2[\"token_start\"], span2[\"token_end\"]):\n",
    "                        label = 1\n",
    "                        break\n",
    "\n",
    "            relation = \"no_relation\" if label == 0 else \"relation\"\n",
    "\n",
    "    \n",
    "            relation_data.append({\n",
    "                \"text\": text,\n",
    "                \"head\": span1[\"text\"],\n",
    "                \"head_type\": span1[\"label\"],\n",
    "                \"child\": span2[\"text\"],\n",
    "                \"child_type\": span2[\"label\"],\n",
    "                \"relation\": relation,\n",
    "                \"label\": label,\n",
    "            })\n",
    "\n",
    "      \n",
    "            if label == 1:\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                negative_count += 1\n",
    "\n",
    "\n",
    "with OUTPUT_FILE.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for item in relation_data:\n",
    "        fw.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Generated {len(relation_data)} relation instances and saved to: {OUTPUT_FILE.resolve()}\")\n",
    "print(f\"Total number of positive instances (label = 1): {positive_count}\")\n",
    "print(f\"Total number of negative instances (label = 0): {negative_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T15:23:18.166107Z",
     "iopub.status.busy": "2025-08-19T15:23:18.165541Z",
     "iopub.status.idle": "2025-08-19T15:23:18.357731Z",
     "shell.execute_reply": "2025-08-19T15:23:18.357008Z",
     "shell.execute_reply.started": "2025-08-19T15:23:18.166077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "INPUT_DIR = Path(\"/kaggle/input/dataset/1\")\n",
    "OUTPUT_FILE = Path(\"merged_full_1.jsonl\")  \n",
    "\n",
    "merged = []\n",
    "relation_count = 0 \n",
    "\n",
    "\n",
    "for full_path in sorted(INPUT_DIR.glob(\"*_full.jsonl\")):\n",
    "    filename = full_path.name\n",
    "    with full_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for lineno, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                print(f\"Skipping empty line at {filename}:{lineno}\")\n",
    "                continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error at {filename}:{lineno} — {e}\")\n",
    "                continue\n",
    "\n",
    "            text = rec.get(\"text\", \"\")\n",
    "            spans = rec.get(\"spans\", [])\n",
    "            relations = rec.get(\"relations\", [])\n",
    "\n",
    "\n",
    "            if not spans:\n",
    "                continue\n",
    "\n",
    "\n",
    "            relation_count += len(relations) \n",
    "\n",
    "            merged.append({\n",
    "                \"text\": text,\n",
    "                \"spans\": spans,\n",
    "                \"relations\": relations\n",
    "            })\n",
    "\n",
    "\n",
    "with OUTPUT_FILE.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for entry in merged:\n",
    "        fw.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "print(f\"Merged and saved {len(merged)} records (text + spans + relations) to: {OUTPUT_FILE.resolve()}\")\n",
    "print(f\"Total number of relation labels annotated: {relation_count}\")\n",
    "\n",
    "\n",
    "\n",
    "INPUT_FILE = Path(\"merged_full_1.jsonl\")\n",
    "OUTPUT_FILE = Path(\"relation_binary_1.jsonl\")\n",
    "\n",
    "relation_data = []\n",
    "positive_count = 0  \n",
    "negative_count = 0  \n",
    "\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        text = record.get(\"text\", \"\")\n",
    "        spans = record.get(\"spans\", [])\n",
    "        relations = record.get(\"relations\", [])\n",
    "\n",
    "        for idx, span in enumerate(spans):\n",
    "            span[\"id\"] = idx\n",
    "\n",
    "        pos2id = {\n",
    "            (span[\"token_start\"], span[\"token_end\"]): span[\"id\"]\n",
    "            for span in spans\n",
    "        }\n",
    "\n",
    "\n",
    "        pos_set = set()  \n",
    "        for span1, span2 in product(spans, spans):\n",
    "            if span1[\"id\"] == span2[\"id\"]:\n",
    "                continue\n",
    "            if span1[\"label\"] != \"PATIENT\":\n",
    "                continue\n",
    "            if span2[\"label\"] not in (\"HPO_TERM\", \"GENE_VARIANT\"):\n",
    "                continue\n",
    "\n",
    "            pair = (span1[\"id\"], span2[\"id\"])\n",
    "\n",
    "            label = 0\n",
    "            for rel in relations:\n",
    "                head_lbl = rel[\"head_span\"].get(\"label\")\n",
    "                child_lbl = rel[\"child_span\"].get(\"label\")\n",
    "                if head_lbl == \"PATIENT\" and child_lbl in (\"HPO_TERM\", \"GENE_VARIANT\"):\n",
    "                    h_key = (rel[\"head_span\"][\"token_start\"], rel[\"head_span\"][\"token_end\"])\n",
    "                    c_key = (rel[\"child_span\"][\"token_start\"], rel[\"child_span\"][\"token_end\"])\n",
    "                    if h_key == (span1[\"token_start\"], span1[\"token_end\"]) and c_key == (span2[\"token_start\"], span2[\"token_end\"]):\n",
    "                        label = 1\n",
    "                        break\n",
    "\n",
    "            relation = \"no_relation\" if label == 0 else \"relation\" \n",
    "\n",
    "\n",
    "            relation_data.append({\n",
    "                \"text\": text,\n",
    "                \"head\": span1[\"text\"],\n",
    "                \"head_type\": span1[\"label\"],\n",
    "                \"child\": span2[\"text\"],\n",
    "                \"child_type\": span2[\"label\"],\n",
    "                \"relation\": relation,\n",
    "                \"label\": label,\n",
    "            })\n",
    "\n",
    "   \n",
    "            if label == 1:\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                negative_count += 1\n",
    "\n",
    "with OUTPUT_FILE.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for item in relation_data:\n",
    "        fw.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Generated {len(relation_data)} relation instances and saved to: {OUTPUT_FILE.resolve()}\")\n",
    "print(f\"Total number of positive instances (label = 1): {positive_count}\")\n",
    "print(f\"Total number of negative instances (label = 0): {negative_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-19T15:25:25.807991Z",
     "iopub.status.busy": "2025-08-19T15:25:25.807787Z",
     "iopub.status.idle": "2025-08-19T15:25:26.221285Z",
     "shell.execute_reply": "2025-08-19T15:25:26.220436Z",
     "shell.execute_reply.started": "2025-08-19T15:25:25.807973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "# Part 1: Merge all files into merged_full_1.jsonl\n",
    "INPUT_DIR = Path(\"/kaggle/input/dataset/1\")\n",
    "OUTPUT_FILE_MERGED = Path(\"merged_full_1.jsonl\")  # Output file for merged data\n",
    "\n",
    "merged = []\n",
    "relation_count = 0  # Count total relations\n",
    "\n",
    "# Merge data from all files\n",
    "for full_path in sorted(INPUT_DIR.glob(\"*_full.jsonl\")):\n",
    "    filename = full_path.name\n",
    "    with full_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for lineno, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                print(f\"Skipping empty line at {filename}:{lineno}\")\n",
    "                continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error at {filename}:{lineno} — {e}\")\n",
    "                continue\n",
    "\n",
    "            text = rec.get(\"text\", \"\")\n",
    "            spans = rec.get(\"spans\", [])\n",
    "            relations = rec.get(\"relations\", [])\n",
    "\n",
    "            # Skip records without spans\n",
    "            if not spans:\n",
    "                continue\n",
    "\n",
    "            # Count relations in this record\n",
    "            relation_count += len(relations)\n",
    "\n",
    "            merged.append({\n",
    "                \"text\": text,\n",
    "                \"spans\": spans,\n",
    "                \"relations\": relations\n",
    "            })\n",
    "\n",
    "# Save merged data to output file\n",
    "with OUTPUT_FILE_MERGED.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for entry in merged:\n",
    "        fw.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Merged and saved {len(merged)} records (text + spans + relations) to: {OUTPUT_FILE_MERGED.resolve()}\")\n",
    "print(f\"Total number of relation labels annotated: {relation_count}\")\n",
    "\n",
    "# Part 2: Generate relation instances\n",
    "INPUT_FILE = Path(\"merged_full_1.jsonl\")\n",
    "OUTPUT_FILE_RELATIONS = Path(\"relation_binary_1.jsonl\")\n",
    "\n",
    "relation_data = []\n",
    "positive_count = 0  # Count positive instances\n",
    "negative_count = 0  # Count negative instances\n",
    "\n",
    "# Read merged input file\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        text = record.get(\"text\", \"\")\n",
    "        spans = record.get(\"spans\", [])\n",
    "        relations = record.get(\"relations\", [])\n",
    "\n",
    "        # 1. Assign unique integer IDs to each span\n",
    "        for idx, span in enumerate(spans):\n",
    "            span[\"id\"] = idx\n",
    "\n",
    "        # 2. Build mapping of token positions to span IDs\n",
    "        pos2id = {\n",
    "            (span[\"token_start\"], span[\"token_end\"]): span[\"id\"]\n",
    "            for span in spans\n",
    "        }\n",
    "\n",
    "        # 3. Collect annotated relation pairs (PATIENT → HPO_TERM or GENE_VARIANT)\n",
    "        pos_set = set()\n",
    "        for rel in relations:\n",
    "            head_lbl = rel[\"head_span\"].get(\"label\")\n",
    "            child_lbl = rel[\"child_span\"].get(\"label\")\n",
    "            if head_lbl == \"PATIENT\" and child_lbl in (\"HPO_TERM\", \"GENE_VARIANT\"):\n",
    "                h_key = (rel[\"head_span\"][\"token_start\"], rel[\"head_span\"][\"token_end\"])\n",
    "                c_key = (rel[\"child_span\"][\"token_start\"], rel[\"child_span\"][\"token_end\"])\n",
    "                if h_key in pos2id and c_key in pos2id:\n",
    "                    head_id = pos2id[h_key]\n",
    "                    child_id = pos2id[c_key]\n",
    "                    pos_set.add((head_id, child_id))\n",
    "\n",
    "        # 4. Generate all possible PATIENT → HPO_TERM or GENE_VARIANT pairs\n",
    "        patients = [s for s in spans if s[\"label\"] == \"PATIENT\"]\n",
    "        targets = [s for s in spans if s[\"label\"] in (\"HPO_TERM\", \"GENE_VARIANT\")]\n",
    "        for span1, span2 in product(patients, targets):\n",
    "            if span1[\"id\"] == span2[\"id\"]:  # Skip same entity\n",
    "                continue\n",
    "\n",
    "            pair = (span1[\"id\"], span2[\"id\"])\n",
    "            # Label as positive if pair exists in pos_set, else negative\n",
    "            label = 1 if pair in pos_set else 0\n",
    "            relation = \"relation\" if label == 1 else \"no_relation\"\n",
    "\n",
    "            # Record relation instance\n",
    "            relation_data.append({\n",
    "                \"text\": text,\n",
    "                \"head\": span1[\"text\"],\n",
    "                \"head_type\": span1[\"label\"],\n",
    "                \"child\": span2[\"text\"],\n",
    "                \"child_type\": span2[\"label\"],\n",
    "                \"relation\": relation,\n",
    "                \"label\": label,\n",
    "            })\n",
    "\n",
    "            # Update counters\n",
    "            if label == 1:\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                negative_count += 1\n",
    "\n",
    "# Save relation instances to output file\n",
    "with OUTPUT_FILE_RELATIONS.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for item in relation_data:\n",
    "        fw.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Generated {len(relation_data)} relation instances and saved to: {OUTPUT_FILE_RELATIONS.resolve()}\")\n",
    "print(f\"Total number of positive instances (label = 1): {positive_count}\")\n",
    "print(f\"Total number of negative instances (label = 0): {negative_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T01:32:15.961620Z",
     "iopub.status.busy": "2025-08-20T01:32:15.960286Z",
     "iopub.status.idle": "2025-08-20T01:32:16.405206Z",
     "shell.execute_reply": "2025-08-20T01:32:16.403597Z",
     "shell.execute_reply.started": "2025-08-20T01:32:15.961571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "INPUT_DIR = Path(\"/kaggle/input/dataset/1\")\n",
    "OUTPUT_FILE_MERGED = Path(\"merged_full_1.jsonl\")\n",
    "\n",
    "merged = []\n",
    "relation_count = 0 \n",
    "\n",
    "\n",
    "for full_path in sorted(INPUT_DIR.glob(\"*_full.jsonl\")):\n",
    "    filename = full_path.name\n",
    "    with full_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for lineno, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "\n",
    "            relations = rec.get(\"relations\", [])\n",
    "            \n",
    "\n",
    "            if not rec.get(\"spans\") and not relations:\n",
    "                continue\n",
    "            \n",
    "\n",
    "            relation_count += len(relations)\n",
    "            \n",
    "\n",
    "            spans = rec.get(\"spans\", [])\n",
    "            \n",
    "\n",
    "            merged.append({\n",
    "                \"text\": rec.get(\"text\", \"\"),\n",
    "                \"spans\": spans,\n",
    "                \"relations\": relations\n",
    "            })\n",
    "\n",
    "\n",
    "with OUTPUT_FILE_MERGED.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for entry in merged:\n",
    "        fw.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Merged {len(merged)} records\")\n",
    "print(f\"Total relations: {relation_count}\")\n",
    "\n",
    "\n",
    "INPUT_FILE = Path(\"merged_full_1.jsonl\")\n",
    "OUTPUT_FILE_RELATIONS = Path(\"relation_binary_1.jsonl\")\n",
    "\n",
    "relation_data = []\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "no_entity_records = 0 \n",
    "no_entity_relations = 0  \n",
    "no_entity_target_relations = 0 \n",
    "\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        text = record[\"text\"]\n",
    "        spans = record[\"spans\"]\n",
    "        relations = record[\"relations\"]\n",
    "        \n",
    "\n",
    "        if not spans:\n",
    "            no_entity_records += 1\n",
    "            no_entity_relations += len(relations)  \n",
    "            \n",
    "\n",
    "            for rel in relations:\n",
    "                head_span = rel[\"head_span\"]\n",
    "                child_span = rel[\"child_span\"]\n",
    "                \n",
    "\n",
    "                if (head_span[\"label\"] == \"PATIENT\" and \n",
    "                    child_span[\"label\"] in (\"HPO_TERM\", \"GENE_VARIANT\")):\n",
    "                    \n",
    "                    no_entity_target_relations += 1 \n",
    "                    \n",
    "\n",
    "                    relation_data.append({\n",
    "                        \"text\": text,\n",
    "                        \"head\": head_span[\"text\"],\n",
    "                        \"head_type\": head_span[\"label\"],\n",
    "                        \"child\": child_span[\"text\"],\n",
    "                        \"child_type\": child_span[\"label\"],\n",
    "                        \"relation\": \"relation\",\n",
    "                        \"label\": 1,\n",
    "                    })\n",
    "                    positive_count += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "        for idx, span in enumerate(spans):\n",
    "            span[\"id\"] = idx\n",
    "\n",
    "        pos2id = {}\n",
    "        for span in spans:\n",
    "            key = (span[\"token_start\"], span[\"token_end\"])\n",
    "            pos2id[key] = span[\"id\"]\n",
    "\n",
    "\n",
    "        positive_relations = set()\n",
    "        for rel in relations:\n",
    "            head_span = rel[\"head_span\"]\n",
    "            child_span = rel[\"child_span\"]\n",
    "    \n",
    "            if (head_span[\"label\"] == \"PATIENT\" and \n",
    "                child_span[\"label\"] in (\"HPO_TERM\", \"GENE_VARIANT\")):\n",
    "                \n",
    "                head_key = (head_span[\"token_start\"], head_span[\"token_end\"])\n",
    "                child_key = (child_span[\"token_start\"], child_span[\"token_end\"])\n",
    "                \n",
    "                if head_key in pos2id and child_key in pos2id:\n",
    "                    positive_relations.add((pos2id[head_key], pos2id[child_key]))\n",
    "\n",
    "\n",
    "        patients = [s for s in spans if s[\"label\"] == \"PATIENT\"]\n",
    "        targets = [s for s in spans if s[\"label\"] in (\"HPO_TERM\", \"GENE_VARIANT\")]\n",
    "        \n",
    "        for patient, target in product(patients, targets):\n",
    "            if patient[\"id\"] == target[\"id\"]:\n",
    "                continue\n",
    "                \n",
    "\n",
    "            is_positive = (patient[\"id\"], target[\"id\"]) in positive_relations\n",
    "            label = 1 if is_positive else 0\n",
    "            \n",
    "            relation_data.append({\n",
    "                \"text\": text,\n",
    "                \"head\": patient[\"text\"],\n",
    "                \"head_type\": patient[\"label\"],\n",
    "                \"child\": target[\"text\"],\n",
    "                \"child_type\": target[\"label\"],\n",
    "                \"relation\": \"relation\" if is_positive else \"no_relation\",\n",
    "                \"label\": label,\n",
    "            })\n",
    "\n",
    "            if is_positive:\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                negative_count += 1\n",
    "\n",
    "\n",
    "with OUTPUT_FILE_RELATIONS.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for item in relation_data:\n",
    "        fw.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Generated {len(relation_data)} relation instances\")\n",
    "print(f\"Positive instances: {positive_count}\")\n",
    "print(f\"Negative instances: {negative_count}\")\n",
    "print(f\"Records without entities but with relations: {no_entity_records}\")\n",
    "print(f\"Total relations in records without entities: {no_entity_relations}\")\n",
    "print(f\"Target relations (PATIENT→HPO_TERM/GENE_VARIANT) in records without entities: {no_entity_target_relations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "INPUT_DIR = Path(\"/kaggle/input/dataset/1\")\n",
    "OUTPUT_FILE_MERGED = Path(\"merged_full_1.jsonl\")\n",
    "\n",
    "merged = []\n",
    "relation_count = 0 \n",
    "\n",
    "for full_path in sorted(INPUT_DIR.glob(\"*_full.jsonl\")):\n",
    "    filename = full_path.name\n",
    "    with full_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for lineno, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rec = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "       \n",
    "            relations = rec.get(\"relations\", [])\n",
    "            \n",
    "     \n",
    "            if not rec.get(\"spans\") and not relations:\n",
    "                continue\n",
    "            \n",
    "            relation_count += len(relations)\n",
    "            \n",
    "\n",
    "            spans = rec.get(\"spans\", [])\n",
    "            \n",
    "\n",
    "            merged.append({\n",
    "                \"text\": rec.get(\"text\", \"\"),\n",
    "                \"spans\": spans,\n",
    "                \"relations\": relations\n",
    "            })\n",
    "\n",
    "with OUTPUT_FILE_MERGED.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for entry in merged:\n",
    "        fw.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Merged {len(merged)} records\")\n",
    "print(f\"Total relations: {relation_count}\")\n",
    "\n",
    "\n",
    "INPUT_FILE = Path(\"merged_full_1.jsonl\")\n",
    "OUTPUT_FILE_RELATIONS = Path(\"relation_binary_1.jsonl\")\n",
    "\n",
    "relation_data = []\n",
    "positive_count = 0\n",
    "negative_count = 0\n",
    "\n",
    "with INPUT_FILE.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        text = record[\"text\"]\n",
    "        spans = record[\"spans\"]\n",
    "        relations = record[\"relations\"]\n",
    "        \n",
    "\n",
    "        if not spans:\n",
    "            continue\n",
    "\n",
    "\n",
    "        for idx, span in enumerate(spans):\n",
    "            span[\"id\"] = idx\n",
    "\n",
    "\n",
    "        pos2id = {}\n",
    "        for span in spans:\n",
    "            key = (span[\"token_start\"], span[\"token_end\"])\n",
    "            pos2id[key] = span[\"id\"]\n",
    "\n",
    "\n",
    "        positive_relations = set()\n",
    "        for rel in relations:\n",
    "            head_span = rel[\"head_span\"]\n",
    "            child_span = rel[\"child_span\"]\n",
    "            \n",
    " \n",
    "            if (head_span[\"label\"] == \"PATIENT\" and \n",
    "                child_span[\"label\"] in (\"HPO_TERM\", \"GENE_VARIANT\")):\n",
    "                \n",
    "                head_key = (head_span[\"token_start\"], head_span[\"token_end\"])\n",
    "                child_key = (child_span[\"token_start\"], child_span[\"token_end\"])\n",
    "                \n",
    "                if head_key in pos2id and child_key in pos2id:\n",
    "                    positive_relations.add((pos2id[head_key], pos2id[child_key]))\n",
    "\n",
    "\n",
    "        patients = [s for s in spans if s[\"label\"] == \"PATIENT\"]\n",
    "        targets = [s for s in spans if s[\"label\"] in (\"HPO_TERM\", \"GENE_VARIANT\")]\n",
    "        \n",
    "        for patient, target in product(patients, targets):\n",
    "            if patient[\"id\"] == target[\"id\"]:\n",
    "                continue\n",
    "                \n",
    "\n",
    "            is_positive = (patient[\"id\"], target[\"id\"]) in positive_relations\n",
    "            label = 1 if is_positive else 0\n",
    "            \n",
    "            relation_data.append({\n",
    "                \"text\": text,\n",
    "                \"head\": patient[\"text\"],\n",
    "                \"head_type\": patient[\"label\"],\n",
    "                \"child\": target[\"text\"],\n",
    "                \"child_type\": target[\"label\"],\n",
    "                \"relation\": \"relation\" if is_positive else \"no_relation\",\n",
    "                \"label\": label,\n",
    "            })\n",
    "\n",
    "            if is_positive:\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                negative_count += 1\n",
    "\n",
    "\n",
    "with OUTPUT_FILE_RELATIONS.open(\"w\", encoding=\"utf-8\") as fw:\n",
    "    for item in relation_data:\n",
    "        fw.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Generated {len(relation_data)} relation instances\")\n",
    "print(f\"Positive instances: {positive_count}\")\n",
    "print(f\"Negative instances: {negative_count}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7727360,
     "sourceId": 12572436,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8098788,
     "sourceId": 12808199,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
